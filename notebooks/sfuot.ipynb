{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genuine users and tweets\n",
    "gen_users = pd.read_csv('dataset/users.csv')\n",
    "gen_tweets = pd.read_csv('dataset/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_digital_dna_from_profile(users_df):\n",
    "    df = users_df\n",
    "    \n",
    "    # Applying necessary replacements\n",
    "    # D - Description is available, E - Description not available\n",
    "    # U - URL is available, V - URL is not available\n",
    "    df['description'] = np.where(pd.isnull(users_df['description']) == True, \"E\", \"D\")\n",
    "    df['url'] = np.where(pd.isnull(users_df['url']) == True, \"V\", \"U\")\n",
    "    \n",
    "    # Changed user data\n",
    "    return df\n",
    "\n",
    "def create_digital_dna_from_tweets(tweets_df):\n",
    "    '''For each user id in tweets_df return a digital DNA string based on posting behaviour.'''\n",
    "    \n",
    "    # Add columns for counts of tweets, replies and retweets.\n",
    "    tweets_df['num_retweets'] = np.where(tweets_df['retweeted_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_replies'] = np.where(tweets_df['in_reply_to_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_tweets'] = np.where((tweets_df['num_retweets'] == 0) & (tweets_df['num_replies'] == 0), 1, 0)\n",
    "\n",
    "    # DNA alphabet for tweet (A), retweet (C) and reply (T).\n",
    "    tweets = tweets_df['num_tweets'] == 1\n",
    "    retweets = tweets_df['num_retweets'] == 1\n",
    "    replies = tweets_df['num_replies'] == 1\n",
    "\n",
    "    tweets_df.loc[:, 'DNA'] = np.where(retweets, 'C', np.where(replies, 'T', 'A'))\n",
    "\n",
    "    # Sort tweets by timestamp.\n",
    "    tweets_df = tweets_df[['user_id', 'timestamp', 'DNA']]\n",
    "    tweets_df = tweets_df.sort_values(by=['timestamp'])\n",
    "\n",
    "    # Create digital DNA string for account.\n",
    "    dna = tweets_df.groupby(by=['user_id'])['DNA'].agg(lambda x: ''.join(x))\n",
    "    \n",
    "    return dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Users shape:', gen_users.shape)\n",
    "print('Tweets shape:', gen_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data which we need\n",
    "filtered_user_data = gen_users.filter([\"id\", \"statuses_count\", \"followers_count\",\n",
    "                                      \"friends_count\", \"favourites_count\", \"listed_count\",\n",
    "                                      \"url\", \"description\", \"timestamp\", \"updated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing user data and tweets of users\n",
    "processed_user_data = create_digital_dna_from_profile(filtered_user_data)\n",
    "processed_user_data['tweets_dna'] = \"\"\n",
    "processed_tweets = create_digital_dna_from_tweets(gen_tweets)\n",
    "\n",
    "print('(Processed) Users shape:', processed_user_data.shape)\n",
    "print('(Processed) Tweets shape:', processed_tweets.shape)\n",
    "\n",
    "# Compile user data with dna tweets\n",
    "for i in range(processed_user_data.shape[0]):\n",
    "    user_id = processed_user_data['id'][i]\n",
    "    dna = processed_tweets[user_id]\n",
    "    processed_user_data['tweets_dna'][i] = dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_account = processed_user_data.filter([\"statuses_count\", \"followers_count\", \"friends_count\", \n",
    "                                              \"favourites_count\", \"listed_count\", \"url\", \"description\",\n",
    "                                              \"timestamp\", \"updated\", \"tweets_dna\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = twitter_account.values.reshape(twitter_account.shape[0], twitter_account.shape[1])\n",
    "input_shape = (1, 10)\n",
    "\n",
    "batch_size = 20\n",
    "no_epochs = 50\n",
    "validation_split = 0.1\n",
    "verbosity = 1\n",
    "\n",
    "latent_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i       = Input(shape=input_shape, name='encoder_input')\n",
    "cx      = Conv2D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(i)\n",
    "cx      = BatchNormalization()(cx)\n",
    "cx      = Conv2D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(cx)\n",
    "cx      = BatchNormalization()(cx)\n",
    "x       = Flatten()(cx)\n",
    "x       = Dense(20, activation='relu')(x)\n",
    "x       = BatchNormalization()(x)\n",
    "mu      = Dense(latent_dim, name='latent_mu')(x)\n",
    "sigma   = Dense(latent_dim, name='latent_sigma')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Conv2D shape for Conv2DTranspose operation in decoder\n",
    "conv_shape = K.int_shape(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling with reparameterization trick\n",
    "def sample_z(args):\n",
    "  mu, sigma = args\n",
    "  batch     = K.shape(mu)[0]\n",
    "  dim       = K.int_shape(mu)[1]\n",
    "  eps       = K.random_normal(shape=(batch, dim))\n",
    "  return mu + K.exp(sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reparameterization trick to ensure correct gradient\n",
    "z       = Lambda(sample_z, output_shape=(latent_dim, ), name='z')([mu, sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate encoder\n",
    "encoder = Model(i, [mu, sigma, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_i   = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "x     = Dense(conv_shape[1] * conv_shape[2] * conv_shape[3], activation='relu')(d_i)\n",
    "x     = BatchNormalization()(x)\n",
    "x     = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
    "cx    = Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "cx    = BatchNormalization()(cx)\n",
    "cx    = Conv2DTranspose(filters=8, kernel_size=3, strides=2, padding='same',  activation='relu')(cx)\n",
    "cx    = BatchNormalization()(cx)\n",
    "o     = Conv2DTranspose(filters=num_channels, kernel_size=3, activation='sigmoid', padding='same', name='decoder_output')(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate decoder\n",
    "decoder = Model(d_i, o, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate VAE\n",
    "vae_outputs = decoder(encoder(i)[2])\n",
    "vae         = Model(i, vae_outputs, name='vae')\n",
    "vae.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
