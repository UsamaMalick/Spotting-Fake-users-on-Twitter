{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genuine users and tweets\n",
    "gen_users = pd.read_csv('dataset/users.csv')\n",
    "gen_tweets = pd.read_csv('dataset/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_digital_dna_from_profile(users_df):\n",
    "    df = users_df\n",
    "    \n",
    "    # Applying necessary replacements\n",
    "    # 1 - Description is available, 0 - Description not available\n",
    "    # 1 - URL is available, 0 - URL is not available\n",
    "    df['description'] = np.where(pd.isnull(users_df['description']) == True, 0, 1)\n",
    "    df['url'] = np.where(pd.isnull(users_df['url']) == True, 0, 1)\n",
    "    \n",
    "    # Changed user data\n",
    "    return df\n",
    "\n",
    "def create_digital_dna_from_tweets(tweets_df):\n",
    "    '''For each user id in tweets_df return a digital DNA string based on posting behaviour.'''\n",
    "    \n",
    "    # Add columns for counts of tweets, replies and retweets.\n",
    "    tweets_df['num_retweets'] = np.where(tweets_df['retweeted_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_replies'] = np.where(tweets_df['in_reply_to_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_tweets'] = np.where((tweets_df['num_retweets'] == 0) & (tweets_df['num_replies'] == 0), 1, 0)\n",
    "    \n",
    "    tweets = tweets_df['num_tweets'] == 1\n",
    "    retweets = tweets_df['num_retweets'] == 1\n",
    "    replies = tweets_df['num_replies'] == 1\n",
    "\n",
    "    # DNA alphabet for tweet (A), retweet (C) and reply (T).\n",
    "    tweets_df.loc[:, 'DNA'] = np.where(retweets, ' C', np.where(replies, ' T', ' A'))\n",
    "\n",
    "    # Sort tweets by timestamp.\n",
    "    tweets_df = tweets_df[['user_id', 'timestamp', 'DNA']]\n",
    "    tweets_df = tweets_df.sort_values(by=['timestamp'])\n",
    "\n",
    "    # Create digital DNA string for account.\n",
    "    dna = tweets_df.groupby(by=['user_id'])['DNA'].agg(lambda x: ''.join(x))\n",
    "    \n",
    "    return dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning float valeus in fields where necessary\n",
    "def time_to_number(time_str):\n",
    "    return np.float32(datetime.fromisoformat(time_str).timestamp())\n",
    "\n",
    "def number_to_float(number):\n",
    "    return np.float32(number)\n",
    "\n",
    "def time_to_float(df, column_name):\n",
    "    for index, value in enumerate(df[column_name]):\n",
    "        df[column_name].at[index] = time_to_number(value)\n",
    "\n",
    "def to_float(df, column_name):\n",
    "    for index, value in enumerate(df[column_name]):\n",
    "        df[column_name].at[index] = number_to_float(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_float(gen_users, \"statuses_count\")\n",
    "to_float(gen_users, \"followers_count\")\n",
    "to_float(gen_users, \"friends_count\")\n",
    "to_float(gen_users, \"favourites_count\")\n",
    "to_float(gen_users, \"listed_count\")\n",
    "\n",
    "time_to_float(gen_users, \"timestamp\")\n",
    "time_to_float(gen_users, \"updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users shape: (100, 42)\n",
      "Tweets shape: (248533, 25)\n"
     ]
    }
   ],
   "source": [
    "print('Users shape:', gen_users.shape)\n",
    "print('Tweets shape:', gen_tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Data - Section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data which we need\n",
    "filtered_user_data = gen_users.filter([\"id\", \"statuses_count\", \"followers_count\",\n",
    "                                      \"friends_count\", \"favourites_count\", \"listed_count\",\n",
    "                                      \"url\", \"description\", \"timestamp\", \"updated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users data shape: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "# Processing user data and tweets of users\n",
    "processed_user_data = create_digital_dna_from_profile(filtered_user_data)\n",
    "print('Users data shape:', processed_user_data.shape)\n",
    "\n",
    "# This code can be used if we change the implementation\n",
    "# and make a single model for both data types\n",
    "# # Compile user data with dna tweets\n",
    "# processed_user_data['tweets_dna'] = \"\"\n",
    "# processed_tweets = create_digital_dna_from_tweets(gen_tweets)\n",
    "# for i in range(processed_user_data.shape[0]):\n",
    "#     user_id = processed_user_data['id'][i]\n",
    "#     dna = processed_tweets[user_id]\n",
    "#     processed_user_data['tweets_dna'].at[i] = dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_account = processed_user_data.filter([\"statuses_count\", \"followers_count\", \"friends_count\", \n",
    "                                              \"favourites_count\", \"listed_count\", \"url\", \"description\",\n",
    "                                              \"timestamp\", \"updated\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60463</td>\n",
       "      <td>568</td>\n",
       "      <td>387</td>\n",
       "      <td>15599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1328857216.0</td>\n",
       "      <td>1458039808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135</td>\n",
       "      <td>208</td>\n",
       "      <td>263</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1253338112.0</td>\n",
       "      <td>1458040064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283536</td>\n",
       "      <td>7785</td>\n",
       "      <td>424</td>\n",
       "      <td>1157</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1241342208.0</td>\n",
       "      <td>1458039296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1770</td>\n",
       "      <td>179</td>\n",
       "      <td>132</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1376278528.0</td>\n",
       "      <td>1458039680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4790</td>\n",
       "      <td>3325</td>\n",
       "      <td>1327</td>\n",
       "      <td>235</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1306796800.0</td>\n",
       "      <td>1458039680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8860</td>\n",
       "      <td>178</td>\n",
       "      <td>493</td>\n",
       "      <td>715</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1256503680.0</td>\n",
       "      <td>1458039808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>12502</td>\n",
       "      <td>478</td>\n",
       "      <td>353</td>\n",
       "      <td>28547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1374653440.0</td>\n",
       "      <td>1458040192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1189</td>\n",
       "      <td>369</td>\n",
       "      <td>337</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1423388032.0</td>\n",
       "      <td>1458039808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>103</td>\n",
       "      <td>26</td>\n",
       "      <td>189</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1340321024.0</td>\n",
       "      <td>1458039808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>48392</td>\n",
       "      <td>1824</td>\n",
       "      <td>499</td>\n",
       "      <td>36945</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1291060864.0</td>\n",
       "      <td>1458039424.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    statuses_count  followers_count  friends_count  favourites_count  \\\n",
       "0            60463              568            387             15599   \n",
       "1              135              208            263                43   \n",
       "2           283536             7785            424              1157   \n",
       "3             1770              179            132              1224   \n",
       "4             4790             3325           1327               235   \n",
       "..             ...              ...            ...               ...   \n",
       "95            8860              178            493               715   \n",
       "96           12502              478            353             28547   \n",
       "97            1189              369            337               250   \n",
       "98             103               26            189                40   \n",
       "99           48392             1824            499             36945   \n",
       "\n",
       "    listed_count  url  description     timestamp       updated  \n",
       "0              1    1            0  1328857216.0  1458039808.0  \n",
       "1              2    0            1  1253338112.0  1458040064.0  \n",
       "2            217    1            1  1241342208.0  1458039296.0  \n",
       "3              0    0            0  1376278528.0  1458039680.0  \n",
       "4              5    1            1  1306796800.0  1458039680.0  \n",
       "..           ...  ...          ...           ...           ...  \n",
       "95             6    0            1  1256503680.0  1458039808.0  \n",
       "96             0    0            1  1374653440.0  1458040192.0  \n",
       "97             0    0            1  1423388032.0  1458039808.0  \n",
       "98             1    0            0  1340321024.0  1458039808.0  \n",
       "99            14    1            1  1291060864.0  1458039424.0  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train      = twitter_account.values.reshape(twitter_account.shape[0], twitter_account.shape[1])\n",
    "\n",
    "batch_size       = 10\n",
    "no_epochs        = 10\n",
    "validation_split = 0.1\n",
    "verbosity        = 1\n",
    "\n",
    "latent_dim       = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dropping tweets data because this model will be trianed just on the user data.\n",
    "Converting all the other fields to float64 then giving it the shape for input.\n",
    "The final variable contains the numpy array made from the dataframe.\n",
    "\"\"\"\n",
    "# Needed in case when we have tweets with user data too\n",
    "# training_data              = twitter_account.drop(['tweets_dna'], axis = 1)\n",
    "training_data              = twitter_account\n",
    "training_data              = training_data.apply(pd.to_numeric)\n",
    "training_data              = training_data.values.reshape(training_data.shape[0], training_data.shape[1])\n",
    "features_in_feature_vector = training_data.shape[1]\n",
    "input_shape                = (features_in_feature_vector, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean               = np.mean(training_data, axis=0)\n",
    "standard_deviation = np.std(training_data, axis=0)\n",
    "training_data      = (training_data - mean) / standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i       = tf.keras.layers.Input(shape=input_shape, name='encoder_input')\n",
    "x       = tf.keras.layers.Dense(features_in_feature_vector, activation='relu')(i)\n",
    "x       = tf.keras.layers.BatchNormalization(name='encoder_output')(x)\n",
    "mu      = tf.keras.layers.Dense(latent_dim, name='latent_mu')(x)\n",
    "sigma   = tf.keras.layers.Dense(latent_dim, name='latent_sigma')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling with reparameterization trick\n",
    "def sample_z(args):\n",
    "    mu, sigma = args\n",
    "    batch     = K.shape(mu)[0]\n",
    "    dim       = K.int_shape(mu)[1]\n",
    "    eps       = K.random_normal(shape=(batch, dim))\n",
    "    return mu + K.exp(sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization for correct gradient\n",
    "z = tf.keras.layers.Lambda(sample_z, output_shape=(latent_dim, ), name='z')([mu, sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 9)            90          encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (BatchNormalizat (None, 9)            36          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "latent_mu (Dense)               (None, 9)            90          encoder_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "latent_sigma (Dense)            (None, 9)            90          encoder_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 9)            0           latent_mu[0][0]                  \n",
      "                                                                 latent_sigma[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 306\n",
      "Trainable params: 288\n",
      "Non-trainable params: 18\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate encoder\n",
    "encoder = tf.keras.Model(i, [mu, sigma, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_i    = tf.keras.layers.Input(shape=(latent_dim, ), name='decoder_input')\n",
    "x      = tf.keras.layers.Dense(features_in_feature_vector, activation='relu')(d_i)\n",
    "x      = tf.keras.layers.Reshape(input_shape)(x)\n",
    "o      = tf.keras.layers.BatchNormalization(name='decoder_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "decoder_output (BatchNormali (None, 9)                 36        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 108\n",
      "Non-trainable params: 18\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate decoder\n",
    "decoder = tf.keras.Model(d_i, o, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE - User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 9), (None, 9), (N 306       \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 9)                 126       \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 396\n",
      "Non-trainable params: 36\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate VAE\n",
    "vae_outputs = decoder(encoder(i)[2])\n",
    "vae         = tf.keras.Model(i, vae_outputs, name='vae')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are calcuating the binary crossentropy here.\n",
    "KL Divergence and Reconstruction are the two\n",
    "metrics which we are using to make prediction.\n",
    "\"\"\"\n",
    "def kl_reconstruction_loss(true, pred):\n",
    "    # Reconstruction loss\n",
    "    reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * input_shape[0]\n",
    "    # KL divergence loss\n",
    "    kl_loss = -0.5 * (1 + sigma - K.square(mu) - K.exp(sigma))\n",
    "    kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "    # Total loss = 50% rec + 50% KL divergence loss\n",
    "    return (reconstruction_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are using the adam optimizer from Keras in combination\n",
    "of our own defined loss function which is the mean of\n",
    "reconstruction loss and the KL divergence.\n",
    "\"\"\"\n",
    "vae.compile(optimizer='adam', loss=kl_reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 221ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 236ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 253ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 272ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1793285ae20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x = training_data, y = training_data, \n",
    "        epochs = no_epochs, \n",
    "        batch_size = batch_size, \n",
    "        validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.265273</td>\n",
       "      <td>-0.197579</td>\n",
       "      <td>-0.174506</td>\n",
       "      <td>1.577222</td>\n",
       "      <td>-0.218345</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-2.478479</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.266865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.498134</td>\n",
       "      <td>-0.255395</td>\n",
       "      <td>-0.289660</td>\n",
       "      <td>-0.568039</td>\n",
       "      <td>-0.211684</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-1.220599</td>\n",
       "      <td>1.114057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.785771</td>\n",
       "      <td>0.961468</td>\n",
       "      <td>-0.140145</td>\n",
       "      <td>-0.414412</td>\n",
       "      <td>1.220414</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-1.436142</td>\n",
       "      <td>-1.427518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.450343</td>\n",
       "      <td>-0.260052</td>\n",
       "      <td>-0.411315</td>\n",
       "      <td>-0.405172</td>\n",
       "      <td>-0.225006</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-2.478479</td>\n",
       "      <td>0.988402</td>\n",
       "      <td>-0.156730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.362067</td>\n",
       "      <td>0.245194</td>\n",
       "      <td>0.698440</td>\n",
       "      <td>-0.541561</td>\n",
       "      <td>-0.191701</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-0.260050</td>\n",
       "      <td>-0.156730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.243100</td>\n",
       "      <td>-0.260213</td>\n",
       "      <td>-0.076067</td>\n",
       "      <td>-0.475366</td>\n",
       "      <td>-0.185040</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-1.163719</td>\n",
       "      <td>0.266865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.136643</td>\n",
       "      <td>-0.212033</td>\n",
       "      <td>-0.206080</td>\n",
       "      <td>3.362825</td>\n",
       "      <td>-0.225006</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>0.959202</td>\n",
       "      <td>1.537653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.467326</td>\n",
       "      <td>-0.229538</td>\n",
       "      <td>-0.220939</td>\n",
       "      <td>-0.539493</td>\n",
       "      <td>-0.225006</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>1.834868</td>\n",
       "      <td>0.266865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.499070</td>\n",
       "      <td>-0.284624</td>\n",
       "      <td>-0.358381</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.218345</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-2.478479</td>\n",
       "      <td>0.342315</td>\n",
       "      <td>0.266865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.912434</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.070495</td>\n",
       "      <td>4.520957</td>\n",
       "      <td>-0.131753</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-0.542794</td>\n",
       "      <td>-1.003922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   1.265273 -0.197579 -0.174506  1.577222 -0.218345  1.333333 -2.478479   \n",
       "1  -0.498134 -0.255395 -0.289660 -0.568039 -0.211684 -0.750000  0.403473   \n",
       "2   7.785771  0.961468 -0.140145 -0.414412  1.220414  1.333333  0.403473   \n",
       "3  -0.450343 -0.260052 -0.411315 -0.405172 -0.225006 -0.750000 -2.478479   \n",
       "4  -0.362067  0.245194  0.698440 -0.541561 -0.191701  1.333333  0.403473   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.243100 -0.260213 -0.076067 -0.475366 -0.185040 -0.750000  0.403473   \n",
       "96 -0.136643 -0.212033 -0.206080  3.362825 -0.225006 -0.750000  0.403473   \n",
       "97 -0.467326 -0.229538 -0.220939 -0.539493 -0.225006 -0.750000  0.403473   \n",
       "98 -0.499070 -0.284624 -0.358381 -0.568453 -0.218345 -0.750000 -2.478479   \n",
       "99  0.912434  0.004134 -0.070495  4.520957 -0.131753  1.333333  0.403473   \n",
       "\n",
       "           7         8  \n",
       "0   0.136333  0.266865  \n",
       "1  -1.220599  1.114057  \n",
       "2  -1.436142 -1.427518  \n",
       "3   0.988402 -0.156730  \n",
       "4  -0.260050 -0.156730  \n",
       "..       ...       ...  \n",
       "95 -1.163719  0.266865  \n",
       "96  0.959202  1.537653  \n",
       "97  1.834868  0.266865  \n",
       "98  0.342315  0.266865  \n",
       "99 -0.542794 -1.003922  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Original Data')\n",
    "pd.DataFrame(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.459924</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>-0.390097</td>\n",
       "      <td>0.306006</td>\n",
       "      <td>0.186672</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>-0.414342</td>\n",
       "      <td>-0.178994</td>\n",
       "      <td>-0.346786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.370724</td>\n",
       "      <td>0.613755</td>\n",
       "      <td>0.725240</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>0.077663</td>\n",
       "      <td>-0.162324</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>0.040184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.549719</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>-0.390097</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>0.807741</td>\n",
       "      <td>4.555582</td>\n",
       "      <td>-0.116114</td>\n",
       "      <td>4.617607</td>\n",
       "      <td>-0.387958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.220392</td>\n",
       "      <td>-0.194841</td>\n",
       "      <td>0.912972</td>\n",
       "      <td>1.014233</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>0.421045</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>-0.364405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051455</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>1.665366</td>\n",
       "      <td>2.095130</td>\n",
       "      <td>0.165052</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>1.559290</td>\n",
       "      <td>1.801005</td>\n",
       "      <td>0.458394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.780359</td>\n",
       "      <td>0.175638</td>\n",
       "      <td>0.145170</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>0.131665</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>0.382156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.320495</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>-0.390097</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>-0.171544</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>-0.414342</td>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.684358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.459924</td>\n",
       "      <td>-0.313995</td>\n",
       "      <td>0.264632</td>\n",
       "      <td>0.272935</td>\n",
       "      <td>0.024236</td>\n",
       "      <td>-0.051141</td>\n",
       "      <td>0.078057</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>-0.387958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.110853</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>0.045516</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>-0.027030</td>\n",
       "      <td>1.568549</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>1.180165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.459924</td>\n",
       "      <td>1.141474</td>\n",
       "      <td>0.501319</td>\n",
       "      <td>2.217683</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>-0.414342</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>-0.387958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -0.459924 -0.361592 -0.390097  0.306006  0.186672 -0.458823 -0.414342   \n",
       "1  -0.370724  0.613755  0.725240 -0.393276 -0.369279  0.077663 -0.162324   \n",
       "2   2.549719 -0.361592 -0.390097 -0.393276  0.807741  4.555582 -0.116114   \n",
       "3  -0.220392 -0.194841  0.912972  1.014233 -0.369279 -0.458823  0.421045   \n",
       "4   0.051455 -0.361592  1.665366  2.095130  0.165052 -0.458823  1.559290   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  1.780359  0.175638  0.145170 -0.393276 -0.369279 -0.458823  0.131665   \n",
       "96 -0.320495 -0.361592 -0.390097 -0.393276 -0.171544 -0.458823 -0.414342   \n",
       "97 -0.459924 -0.313995  0.264632  0.272935  0.024236 -0.051141  0.078057   \n",
       "98  1.110853 -0.361592  0.045516 -0.393276 -0.027030  1.568549  0.043900   \n",
       "99 -0.459924  1.141474  0.501319  2.217683 -0.369279 -0.458823 -0.414342   \n",
       "\n",
       "           7         8  \n",
       "0  -0.178994 -0.346786  \n",
       "1  -0.327061  0.040184  \n",
       "2   4.617607 -0.387958  \n",
       "3  -0.327061 -0.364405  \n",
       "4   1.801005  0.458394  \n",
       "..       ...       ...  \n",
       "95 -0.327061  0.382156  \n",
       "96  0.252296  0.684358  \n",
       "97 -0.327061 -0.387958  \n",
       "98 -0.327061  1.180165  \n",
       "99 -0.327061 -0.387958  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predicted Data')\n",
    "pd.DataFrame(vae.predict(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "tweets_dna = create_digital_dna_from_tweets(gen_tweets).to_numpy()\n",
    "print('Tweets shape:', tweets_dna.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part is being used to generate vocabulory which will be used to\n",
    "convert the text into indices. Then this data can be converted to\n",
    "matrices and fed to the learning models.\n",
    "Sequence legth is set by checkcing the maximum lenth of string in the\n",
    "dataset so that we don't have to lose any detail which help in\n",
    "converting the representation back to the original text.\n",
    "\"\"\"\n",
    "VOCAB_SIZE = 5\n",
    "MAX_SEQUENCE_LENGHT = 3500\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE, output_sequence_length=MAX_SEQUENCE_LENGHT)\n",
    "encoder.adapt(tweets_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '[UNK]' 'a' 'c' 't']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking if the generated tokens are right which\n",
    "will be used as terms for strigs.\n",
    "\"\"\"\n",
    "vocab = np.array(encoder.get_vocabulary())\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A T A A A A A A T T A A A T A T A A A T A A A T A A T A T T A T T A A A A A A A A A A A A A A A A A A A A T A A A A A A T A A A A A A A A A A A A A A A A T A A T A T A A A A A A T A A A A A A A A A A A A A A A A A T A A T T A A A A A T T A A T T T A A A T A A A A A T A T A A A A A A A A A A T T A T A T T T A T A A A T A T A A A T A A A A A A A T A A A A A T T A A T A A A A T A A A A T A A A A T T A T T T T A T T T T A A A A T T A A A T A T T A T A A A A A T T A A A T T A A T T A T T T A T T A A T T A A T T T T T A T A A T T T A A T T A T T T T A A T T A A T A A T T T T T T A A A A T A T A T T A T A T T A A A A A A A T T T T A T A T A A T A A A A T T T T T T T T T T T T T T T T T T T A T A T T A T A T T T T T A T T A A A A T A A T T A A T A A T A A T A A A T A A A A A A T T A A A A A T T T A C A T C A A C A A A C T A T A C T C A T C T A T T A A A A A T A C T T C A A A C C A A C C C C A A T A A A T A A A A A A A C C C A A C T T T T A A A A A A A A A A A A T A A A A A T A A A A A A A A A A A A C A A C C A C A A A A A C A C T T A T A A C C A A A C A C A A A A A A A A A A A A A A A A A A A A A A A T A T A A C C C C C C A A C T A C A C A C C A A A A A C A C C C C A A A\n",
      "Processed:  a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a t a a a a a a t t a a a t a t a a a t a a a t a a t a t t a t t a a a a a a a a a a a a a a a a a a a a t a a a a a a t a a a a a a a a a a a a a a a a t a a t a t a a a a a a t a a a a a a a a a a a a a a a a a t a a t t a a a a a t t a a t t t a a a t a a a a a t a t a a a a a a a a a a t t a t a t t t a t a a a t a t a a a t a a a a a a a t a a a a a t t a a t a a a a t a a a a t a a a a t t a t t t t a t t t t a a a a t t a a a t a t t a t a a a a a t t a a a t t a a t t a t t t a t t a a t t a a t t t t t a t a a t t t a a t t a t t t t a a t t a a t a a t t t t t t a a a a t a t a t t a t a t t a a a a a a a t t t t a t a t a a t a a a a t t t t t t t t t t t t t t t t t t t a t a t t a t a t t t t t a t t a a a a t a a t t a a t a a t a a t a a a t a a a a a a t t a a a a a t t t a c a t c a a c a a a c t a t a c t c a t c t a t t a a a a a t a c t t c a a a c c a a c c c c a a t a a a t a a a a a a a c c c a a c t t t t a a a a a a a a a a a a t a a a a a t a a a a a a a a a a a a c a a c c a c a a a a a c a c t t a t a a c c a a a c a c a a a a a a a a a a a a a a a a a a a a a a a t a t a a c c c c c c a a c t a c a c a c c a a a a a c a c c c c a a a                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking if the original and the processed data\n",
    "because presence of unknown chunks would make it\n",
    "impossible to convert data back to text.\n",
    "\"\"\"\n",
    "encoded_example = encoder(tweets_dna)[:3].numpy()\n",
    "\n",
    "for n in range(1):\n",
    "    print(\"Original: \", tweets_dna[n])\n",
    "    print(\"Processed: \", \" \".join(vocab[encoded_example[n]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input_shape                 = (encoder(tweets_dna).shape[1], )\n",
    "text_input_diensions             = len(encoder.get_vocabulary())\n",
    "text_embedding_output_dimensions = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input       = tf.keras.layers.Input(shape=text_input_shape)\n",
    "embedding_layer     = tf.keras.layers.Embedding(input_dim=text_input_diensions, output_dim=text_embedding_output_dimensions, mask_zero=True)(encoder_input)\n",
    "LTSM_layer          = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(text_embedding_output_dimensions))(embedding_layer)\n",
    "dense_layer         = tf.keras.layers.Dense(text_embedding_output_dimensions, activation='relu')(LTSM_layer)\n",
    "dense_final_layer   = tf.keras.layers.Dense(1)(dense_layer)\n",
    "text_mu             = tf.keras.layers.Dense(text_input_diensions, name='text_latent_mu')(dense_final_layer)\n",
    "text_sigma          = tf.keras.layers.Dense(text_input_diensions, name='text_latent_sigma')(dense_final_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling with reparameterization trick\n",
    "def sample_z(args):\n",
    "    mu, sigma = args\n",
    "    batch     = tf.keras.backend.shape(text_mu)[0]\n",
    "    dim       = tf.keras.backend.int_shape(text_mu)[1]\n",
    "    eps       = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return text_mu + tf.keras.backend.exp(text_sigma / 2) * eps\n",
    "\n",
    "z = tf.keras.layers.Lambda(sample_z, output_shape=(len(encoder.get_vocabulary()), ), name='z')([text_mu, text_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(encoder_input, [text_mu, text_sigma, z], name='Text Compression Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Text Compression Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 3500, 64)     320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128)          66048       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "text_latent_mu (Dense)          (None, 5)            10          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "text_latent_sigma (Dense)       (None, 5)            10          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 5)            0           text_latent_mu[0][0]             \n",
      "                                                                 text_latent_sigma[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 74,709\n",
      "Trainable params: 74,709\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE - Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
