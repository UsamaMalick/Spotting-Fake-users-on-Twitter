{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genuine users and tweets\n",
    "gen_users = pd.read_csv('dataset/users.csv')\n",
    "gen_tweets = pd.read_csv('dataset/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_digital_dna_from_profile(users_df):\n",
    "    df = users_df\n",
    "    \n",
    "    # Applying necessary replacements\n",
    "    # 1 - Description is available, 0 - Description not available\n",
    "    # 1 - URL is available, 0 - URL is not available\n",
    "    df['description'] = np.where(pd.isnull(users_df['description']) == True, 0, 1)\n",
    "    df['url'] = np.where(pd.isnull(users_df['url']) == True, 0, 1)\n",
    "    \n",
    "    # Changed user data\n",
    "    return df\n",
    "\n",
    "def create_digital_dna_from_tweets(tweets_df):\n",
    "    '''For each user id in tweets_df return a digital DNA string based on posting behaviour.'''\n",
    "    \n",
    "    # Add columns for counts of tweets, replies and retweets.\n",
    "    tweets_df['num_retweets'] = np.where(tweets_df['retweeted_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_replies'] = np.where(tweets_df['in_reply_to_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_tweets'] = np.where((tweets_df['num_retweets'] == 0) & (tweets_df['num_replies'] == 0), 1, 0)\n",
    "    \n",
    "    tweets = tweets_df['num_tweets'] == 1\n",
    "    retweets = tweets_df['num_retweets'] == 1\n",
    "    replies = tweets_df['num_replies'] == 1\n",
    "\n",
    "    # DNA alphabet for tweet (A), retweet (C) and reply (T).\n",
    "    tweets_df.loc[:, 'DNA'] = np.where(retweets, ' C', np.where(replies, ' T', ' A'))\n",
    "\n",
    "    # Sort tweets by timestamp.\n",
    "    tweets_df = tweets_df[['user_id', 'timestamp', 'DNA']]\n",
    "    tweets_df = tweets_df.sort_values(by=['timestamp'])\n",
    "\n",
    "    # Create digital DNA string for account.\n",
    "    dna = tweets_df.groupby(by=['user_id'])['DNA'].agg(lambda x: ''.join(x))\n",
    "    \n",
    "    return dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning float valeus in fields where necessary\n",
    "def time_to_number(time_str):\n",
    "    return np.float32(datetime.fromisoformat(time_str).timestamp())\n",
    "\n",
    "def number_to_float(number):\n",
    "    return np.float32(number)\n",
    "\n",
    "def time_to_float(df, column_name):\n",
    "    for index, value in enumerate(df[column_name]):\n",
    "        df[column_name].at[index] = time_to_number(value)\n",
    "\n",
    "def to_float(df, column_name):\n",
    "    for index, value in enumerate(df[column_name]):\n",
    "        df[column_name].at[index] = number_to_float(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_float(gen_users, \"statuses_count\")\n",
    "to_float(gen_users, \"followers_count\")\n",
    "to_float(gen_users, \"friends_count\")\n",
    "to_float(gen_users, \"favourites_count\")\n",
    "to_float(gen_users, \"listed_count\")\n",
    "\n",
    "time_to_float(gen_users, \"timestamp\")\n",
    "time_to_float(gen_users, \"updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users shape: (100, 42)\n",
      "Tweets shape: (248533, 25)\n"
     ]
    }
   ],
   "source": [
    "print('Users shape:', gen_users.shape)\n",
    "print('Tweets shape:', gen_tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Data - Section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data which we need\n",
    "filtered_user_data = gen_users.filter([\"id\", \"statuses_count\", \"followers_count\",\n",
    "                                      \"friends_count\", \"favourites_count\", \"listed_count\",\n",
    "                                      \"url\", \"description\", \"timestamp\", \"updated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users data shape: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "# Processing user data and tweets of users\n",
    "processed_user_data = create_digital_dna_from_profile(filtered_user_data)\n",
    "print('Users data shape:', processed_user_data.shape)\n",
    "\n",
    "# This code can be used if we change the implementation\n",
    "# and make a single model for both data types\n",
    "# # Compile user data with dna tweets\n",
    "# processed_user_data['tweets_dna'] = \"\"\n",
    "# processed_tweets = create_digital_dna_from_tweets(gen_tweets)\n",
    "# for i in range(processed_user_data.shape[0]):\n",
    "#     user_id = processed_user_data['id'][i]\n",
    "#     dna = processed_tweets[user_id]\n",
    "#     processed_user_data['tweets_dna'].at[i] = dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_account = processed_user_data.filter([\"statuses_count\", \"followers_count\", \"friends_count\", \n",
    "                                              \"favourites_count\", \"listed_count\", \"url\", \"description\",\n",
    "                                              \"timestamp\", \"updated\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60463</td>\n",
       "      <td>568</td>\n",
       "      <td>387</td>\n",
       "      <td>15599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1328857216.0</td>\n",
       "      <td>1458039808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135</td>\n",
       "      <td>208</td>\n",
       "      <td>263</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1253338112.0</td>\n",
       "      <td>1458040064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283536</td>\n",
       "      <td>7785</td>\n",
       "      <td>424</td>\n",
       "      <td>1157</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1241342208.0</td>\n",
       "      <td>1458039296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1770</td>\n",
       "      <td>179</td>\n",
       "      <td>132</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1376278528.0</td>\n",
       "      <td>1458039680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4790</td>\n",
       "      <td>3325</td>\n",
       "      <td>1327</td>\n",
       "      <td>235</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1306796800.0</td>\n",
       "      <td>1458039680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8860</td>\n",
       "      <td>178</td>\n",
       "      <td>493</td>\n",
       "      <td>715</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1256503680.0</td>\n",
       "      <td>1458039808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>12502</td>\n",
       "      <td>478</td>\n",
       "      <td>353</td>\n",
       "      <td>28547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1374653440.0</td>\n",
       "      <td>1458040192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1189</td>\n",
       "      <td>369</td>\n",
       "      <td>337</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1423388032.0</td>\n",
       "      <td>1458039808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>103</td>\n",
       "      <td>26</td>\n",
       "      <td>189</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1340321024.0</td>\n",
       "      <td>1458039808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>48392</td>\n",
       "      <td>1824</td>\n",
       "      <td>499</td>\n",
       "      <td>36945</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1291060864.0</td>\n",
       "      <td>1458039424.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    statuses_count  followers_count  friends_count  favourites_count  \\\n",
       "0            60463              568            387             15599   \n",
       "1              135              208            263                43   \n",
       "2           283536             7785            424              1157   \n",
       "3             1770              179            132              1224   \n",
       "4             4790             3325           1327               235   \n",
       "..             ...              ...            ...               ...   \n",
       "95            8860              178            493               715   \n",
       "96           12502              478            353             28547   \n",
       "97            1189              369            337               250   \n",
       "98             103               26            189                40   \n",
       "99           48392             1824            499             36945   \n",
       "\n",
       "    listed_count  url  description     timestamp       updated  \n",
       "0              1    1            0  1328857216.0  1458039808.0  \n",
       "1              2    0            1  1253338112.0  1458040064.0  \n",
       "2            217    1            1  1241342208.0  1458039296.0  \n",
       "3              0    0            0  1376278528.0  1458039680.0  \n",
       "4              5    1            1  1306796800.0  1458039680.0  \n",
       "..           ...  ...          ...           ...           ...  \n",
       "95             6    0            1  1256503680.0  1458039808.0  \n",
       "96             0    0            1  1374653440.0  1458040192.0  \n",
       "97             0    0            1  1423388032.0  1458039808.0  \n",
       "98             1    0            0  1340321024.0  1458039808.0  \n",
       "99            14    1            1  1291060864.0  1458039424.0  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train      = twitter_account.values.reshape(twitter_account.shape[0], twitter_account.shape[1])\n",
    "\n",
    "batch_size       = 10\n",
    "no_epochs        = 10\n",
    "validation_split = 0.1\n",
    "verbosity        = 1\n",
    "\n",
    "latent_dim       = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dropping tweets data because this model will be trianed just on the user data.\n",
    "Converting all the other fields to float64 then giving it the shape for input.\n",
    "The final variable contains the numpy array made from the dataframe.\n",
    "\"\"\"\n",
    "# Needed in case when we have tweets with user data too\n",
    "# training_data              = twitter_account.drop(['tweets_dna'], axis = 1)\n",
    "training_data              = twitter_account\n",
    "training_data              = training_data.apply(pd.to_numeric)\n",
    "training_data              = training_data.values.reshape(training_data.shape[0], training_data.shape[1])\n",
    "features_in_feature_vector = training_data.shape[1]\n",
    "input_shape                = (features_in_feature_vector, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean               = np.mean(training_data, axis=0)\n",
    "standard_deviation = np.std(training_data, axis=0)\n",
    "training_data      = (training_data - mean) / standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i       = tf.keras.layers.Input(shape=input_shape, name='encoder_input')\n",
    "x       = tf.keras.layers.Dense(features_in_feature_vector, activation='relu')(i)\n",
    "x       = tf.keras.layers.BatchNormalization(name='encoder_output')(x)\n",
    "mu      = tf.keras.layers.Dense(latent_dim, name='latent_mu')(x)\n",
    "sigma   = tf.keras.layers.Dense(latent_dim, name='latent_sigma')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling with reparameterization trick\n",
    "def sample_z(args):\n",
    "    mu, sigma = args\n",
    "    batch     = K.shape(mu)[0]\n",
    "    dim       = K.int_shape(mu)[1]\n",
    "    eps       = K.random_normal(shape=(batch, dim))\n",
    "    return mu + K.exp(sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization for correct gradient\n",
    "z = tf.keras.layers.Lambda(sample_z, output_shape=(latent_dim, ), name='z')([mu, sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 9)            90          encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (BatchNormalizat (None, 9)            36          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "latent_mu (Dense)               (None, 9)            90          encoder_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "latent_sigma (Dense)            (None, 9)            90          encoder_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 9)            0           latent_mu[0][0]                  \n",
      "                                                                 latent_sigma[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 306\n",
      "Trainable params: 288\n",
      "Non-trainable params: 18\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate encoder\n",
    "encoder = tf.keras.Model(i, [mu, sigma, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_i    = tf.keras.layers.Input(shape=(latent_dim, ), name='decoder_input')\n",
    "x      = tf.keras.layers.Dense(features_in_feature_vector, activation='relu')(d_i)\n",
    "x      = tf.keras.layers.Reshape(input_shape)(x)\n",
    "o      = tf.keras.layers.BatchNormalization(name='decoder_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "decoder_output (BatchNormali (None, 9)                 36        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 108\n",
      "Non-trainable params: 18\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate decoder\n",
    "decoder = tf.keras.Model(d_i, o, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE - User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 9), (None, 9), (N 306       \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 9)                 126       \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 396\n",
      "Non-trainable params: 36\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate VAE\n",
    "vae_outputs = decoder(encoder(i)[2])\n",
    "vae         = tf.keras.Model(i, vae_outputs, name='User Data-VAE')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are calcuating the binary crossentropy here.\n",
    "KL Divergence and Reconstruction are the two\n",
    "metrics which we are using to make prediction.\n",
    "\"\"\"\n",
    "def kl_reconstruction_loss(true, pred):\n",
    "    # Reconstruction loss\n",
    "    reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * input_shape[0]\n",
    "    # KL divergence loss\n",
    "    kl_loss = -0.5 * (1 + sigma - K.square(mu) - K.exp(sigma))\n",
    "    kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "    # Total loss = 50% rec + 50% KL divergence loss\n",
    "    return (reconstruction_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are using the adam optimizer from Keras in combination\n",
    "of our own defined loss function which is the mean of\n",
    "reconstruction loss and the KL divergence.\n",
    "\"\"\"\n",
    "vae.compile(optimizer='adam', loss=kl_reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 248ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 234ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 218ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 255ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 220ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 3s 289ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 216ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = vae.fit(x = training_data, y = training_data, \n",
    "        epochs = no_epochs, \n",
    "        batch_size = batch_size, \n",
    "        validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17985d1d400>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.265273</td>\n",
       "      <td>-0.197579</td>\n",
       "      <td>-0.174506</td>\n",
       "      <td>1.577222</td>\n",
       "      <td>-0.218345</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-2.478479</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.266865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.498134</td>\n",
       "      <td>-0.255395</td>\n",
       "      <td>-0.289660</td>\n",
       "      <td>-0.568039</td>\n",
       "      <td>-0.211684</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-1.220599</td>\n",
       "      <td>1.114057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.785771</td>\n",
       "      <td>0.961468</td>\n",
       "      <td>-0.140145</td>\n",
       "      <td>-0.414412</td>\n",
       "      <td>1.220414</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-1.436142</td>\n",
       "      <td>-1.427518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.450343</td>\n",
       "      <td>-0.260052</td>\n",
       "      <td>-0.411315</td>\n",
       "      <td>-0.405172</td>\n",
       "      <td>-0.225006</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-2.478479</td>\n",
       "      <td>0.988402</td>\n",
       "      <td>-0.156730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.362067</td>\n",
       "      <td>0.245194</td>\n",
       "      <td>0.698440</td>\n",
       "      <td>-0.541561</td>\n",
       "      <td>-0.191701</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-0.260050</td>\n",
       "      <td>-0.156730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.243100</td>\n",
       "      <td>-0.260213</td>\n",
       "      <td>-0.076067</td>\n",
       "      <td>-0.475366</td>\n",
       "      <td>-0.185040</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-1.163719</td>\n",
       "      <td>0.266865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.136643</td>\n",
       "      <td>-0.212033</td>\n",
       "      <td>-0.206080</td>\n",
       "      <td>3.362825</td>\n",
       "      <td>-0.225006</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>0.959202</td>\n",
       "      <td>1.537653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.467326</td>\n",
       "      <td>-0.229538</td>\n",
       "      <td>-0.220939</td>\n",
       "      <td>-0.539493</td>\n",
       "      <td>-0.225006</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>1.834868</td>\n",
       "      <td>0.266865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.499070</td>\n",
       "      <td>-0.284624</td>\n",
       "      <td>-0.358381</td>\n",
       "      <td>-0.568453</td>\n",
       "      <td>-0.218345</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-2.478479</td>\n",
       "      <td>0.342315</td>\n",
       "      <td>0.266865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.912434</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.070495</td>\n",
       "      <td>4.520957</td>\n",
       "      <td>-0.131753</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>-0.542794</td>\n",
       "      <td>-1.003922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   1.265273 -0.197579 -0.174506  1.577222 -0.218345  1.333333 -2.478479   \n",
       "1  -0.498134 -0.255395 -0.289660 -0.568039 -0.211684 -0.750000  0.403473   \n",
       "2   7.785771  0.961468 -0.140145 -0.414412  1.220414  1.333333  0.403473   \n",
       "3  -0.450343 -0.260052 -0.411315 -0.405172 -0.225006 -0.750000 -2.478479   \n",
       "4  -0.362067  0.245194  0.698440 -0.541561 -0.191701  1.333333  0.403473   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.243100 -0.260213 -0.076067 -0.475366 -0.185040 -0.750000  0.403473   \n",
       "96 -0.136643 -0.212033 -0.206080  3.362825 -0.225006 -0.750000  0.403473   \n",
       "97 -0.467326 -0.229538 -0.220939 -0.539493 -0.225006 -0.750000  0.403473   \n",
       "98 -0.499070 -0.284624 -0.358381 -0.568453 -0.218345 -0.750000 -2.478479   \n",
       "99  0.912434  0.004134 -0.070495  4.520957 -0.131753  1.333333  0.403473   \n",
       "\n",
       "           7         8  \n",
       "0   0.136333  0.266865  \n",
       "1  -1.220599  1.114057  \n",
       "2  -1.436142 -1.427518  \n",
       "3   0.988402 -0.156730  \n",
       "4  -0.260050 -0.156730  \n",
       "..       ...       ...  \n",
       "95 -1.163719  0.266865  \n",
       "96  0.959202  1.537653  \n",
       "97  1.834868  0.266865  \n",
       "98  0.342315  0.266865  \n",
       "99 -0.542794 -1.003922  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Original Data')\n",
    "pd.DataFrame(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.459924</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>-0.390097</td>\n",
       "      <td>0.306006</td>\n",
       "      <td>0.186672</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>-0.414342</td>\n",
       "      <td>-0.178994</td>\n",
       "      <td>-0.346786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.370724</td>\n",
       "      <td>0.613755</td>\n",
       "      <td>0.725240</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>0.077663</td>\n",
       "      <td>-0.162324</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>0.040184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.549719</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>-0.390097</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>0.807741</td>\n",
       "      <td>4.555582</td>\n",
       "      <td>-0.116114</td>\n",
       "      <td>4.617607</td>\n",
       "      <td>-0.387958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.220392</td>\n",
       "      <td>-0.194841</td>\n",
       "      <td>0.912972</td>\n",
       "      <td>1.014233</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>0.421045</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>-0.364405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051455</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>1.665366</td>\n",
       "      <td>2.095130</td>\n",
       "      <td>0.165052</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>1.559290</td>\n",
       "      <td>1.801005</td>\n",
       "      <td>0.458394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.780359</td>\n",
       "      <td>0.175638</td>\n",
       "      <td>0.145170</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>0.131665</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>0.382156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.320495</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>-0.390097</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>-0.171544</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>-0.414342</td>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.684358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.459924</td>\n",
       "      <td>-0.313995</td>\n",
       "      <td>0.264632</td>\n",
       "      <td>0.272935</td>\n",
       "      <td>0.024236</td>\n",
       "      <td>-0.051141</td>\n",
       "      <td>0.078057</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>-0.387958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.110853</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>0.045516</td>\n",
       "      <td>-0.393276</td>\n",
       "      <td>-0.027030</td>\n",
       "      <td>1.568549</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>1.180165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.459924</td>\n",
       "      <td>1.141474</td>\n",
       "      <td>0.501319</td>\n",
       "      <td>2.217683</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>-0.458823</td>\n",
       "      <td>-0.414342</td>\n",
       "      <td>-0.327061</td>\n",
       "      <td>-0.387958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -0.459924 -0.361592 -0.390097  0.306006  0.186672 -0.458823 -0.414342   \n",
       "1  -0.370724  0.613755  0.725240 -0.393276 -0.369279  0.077663 -0.162324   \n",
       "2   2.549719 -0.361592 -0.390097 -0.393276  0.807741  4.555582 -0.116114   \n",
       "3  -0.220392 -0.194841  0.912972  1.014233 -0.369279 -0.458823  0.421045   \n",
       "4   0.051455 -0.361592  1.665366  2.095130  0.165052 -0.458823  1.559290   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  1.780359  0.175638  0.145170 -0.393276 -0.369279 -0.458823  0.131665   \n",
       "96 -0.320495 -0.361592 -0.390097 -0.393276 -0.171544 -0.458823 -0.414342   \n",
       "97 -0.459924 -0.313995  0.264632  0.272935  0.024236 -0.051141  0.078057   \n",
       "98  1.110853 -0.361592  0.045516 -0.393276 -0.027030  1.568549  0.043900   \n",
       "99 -0.459924  1.141474  0.501319  2.217683 -0.369279 -0.458823 -0.414342   \n",
       "\n",
       "           7         8  \n",
       "0  -0.178994 -0.346786  \n",
       "1  -0.327061  0.040184  \n",
       "2   4.617607 -0.387958  \n",
       "3  -0.327061 -0.364405  \n",
       "4   1.801005  0.458394  \n",
       "..       ...       ...  \n",
       "95 -0.327061  0.382156  \n",
       "96  0.252296  0.684358  \n",
       "97 -0.327061 -0.387958  \n",
       "98 -0.327061  1.180165  \n",
       "99 -0.327061 -0.387958  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predicted Data')\n",
    "pd.DataFrame(vae.predict(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "tweets_dna = create_digital_dna_from_tweets(gen_tweets).to_numpy()\n",
    "print('Tweets shape:', tweets_dna.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part is being used to generate vocabulory which will be used to\n",
    "convert the text into indices. Then this data can be converted to\n",
    "matrices and fed to the learning models.\n",
    "Sequence legth is set by checkcing the maximum lenth of string in the\n",
    "dataset so that we don't have to lose any detail which help in\n",
    "converting the representation back to the original text.\n",
    "\"\"\"\n",
    "VOCAB_SIZE = 5\n",
    "MAX_SEQUENCE_LENGHT = 3500\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE, output_sequence_length=MAX_SEQUENCE_LENGHT)\n",
    "encoder.adapt(tweets_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '[UNK]' 'a' 'c' 't']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking if the generated tokens are right which\n",
    "will be used as terms for strigs.\n",
    "\"\"\"\n",
    "vocab = np.array(encoder.get_vocabulary())\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A T A A A A A A T T A A A T A T A A A T A A A T A A T A T T A T T A A A A A A A A A A A A A A A A A A A A T A A A A A A T A A A A A A A A A A A A A A A A T A A T A T A A A A A A T A A A A A A A A A A A A A A A A A T A A T T A A A A A T T A A T T T A A A T A A A A A T A T A A A A A A A A A A T T A T A T T T A T A A A T A T A A A T A A A A A A A T A A A A A T T A A T A A A A T A A A A T A A A A T T A T T T T A T T T T A A A A T T A A A T A T T A T A A A A A T T A A A T T A A T T A T T T A T T A A T T A A T T T T T A T A A T T T A A T T A T T T T A A T T A A T A A T T T T T T A A A A T A T A T T A T A T T A A A A A A A T T T T A T A T A A T A A A A T T T T T T T T T T T T T T T T T T T A T A T T A T A T T T T T A T T A A A A T A A T T A A T A A T A A T A A A T A A A A A A T T A A A A A T T T A C A T C A A C A A A C T A T A C T C A T C T A T T A A A A A T A C T T C A A A C C A A C C C C A A T A A A T A A A A A A A C C C A A C T T T T A A A A A A A A A A A A T A A A A A T A A A A A A A A A A A A C A A C C A C A A A A A C A C T T A T A A C C A A A C A C A A A A A A A A A A A A A A A A A A A A A A A T A T A A C C C C C C A A C T A C A C A C C A A A A A C A C C C C A A A\n",
      "Processed:  a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a t a a a a a a t t a a a t a t a a a t a a a t a a t a t t a t t a a a a a a a a a a a a a a a a a a a a t a a a a a a t a a a a a a a a a a a a a a a a t a a t a t a a a a a a t a a a a a a a a a a a a a a a a a t a a t t a a a a a t t a a t t t a a a t a a a a a t a t a a a a a a a a a a t t a t a t t t a t a a a t a t a a a t a a a a a a a t a a a a a t t a a t a a a a t a a a a t a a a a t t a t t t t a t t t t a a a a t t a a a t a t t a t a a a a a t t a a a t t a a t t a t t t a t t a a t t a a t t t t t a t a a t t t a a t t a t t t t a a t t a a t a a t t t t t t a a a a t a t a t t a t a t t a a a a a a a t t t t a t a t a a t a a a a t t t t t t t t t t t t t t t t t t t a t a t t a t a t t t t t a t t a a a a t a a t t a a t a a t a a t a a a t a a a a a a t t a a a a a t t t a c a t c a a c a a a c t a t a c t c a t c t a t t a a a a a t a c t t c a a a c c a a c c c c a a t a a a t a a a a a a a c c c a a c t t t t a a a a a a a a a a a a t a a a a a t a a a a a a a a a a a a c a a c c a c a a a a a c a c t t a t a a c c a a a c a c a a a a a a a a a a a a a a a a a a a a a a a t a t a a c c c c c c a a c t a c a c a c c a a a a a c a c c c c a a a                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking if the original and the processed data\n",
    "because presence of unknown chunks would make it\n",
    "impossible to convert data back to text.\n",
    "\"\"\"\n",
    "encoded_example = encoder(tweets_dna)[:3].numpy()\n",
    "\n",
    "for n in range(1):\n",
    "    print(\"Original: \", tweets_dna[n])\n",
    "    print(\"Processed: \", \" \".join(vocab[encoded_example[n]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input_shape                 = (encoder(tweets_dna).shape[1], )\n",
    "text_input_diensions             = len(encoder.get_vocabulary())\n",
    "text_embedding_output_dimensions = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input                                              = tf.keras.layers.Input(shape=text_input_shape)\n",
    "embedding_layer                                            = tf.keras.layers.Embedding(input_dim=text_input_diensions, output_dim=text_embedding_output_dimensions, mask_zero=True)(encoder_input)\n",
    "LTSM_layer, forward_h, forward_c, backward_h, backward_c   = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(text_embedding_output_dimensions, return_state=True))(embedding_layer)\n",
    "dense_layer                                                = tf.keras.layers.Dense(text_embedding_output_dimensions, activation='relu')(LTSM_layer)\n",
    "dense_final_layer                                          = tf.keras.layers.Dense(1)(dense_layer)\n",
    "text_mu                                                    = tf.keras.layers.Dense(text_input_diensions, name='text_latent_mu')(dense_final_layer)\n",
    "text_sigma                                                 = tf.keras.layers.Dense(text_input_diensions, name='text_latent_sigma')(dense_final_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder_states = [forward_h, forward_c, backward_h, backward_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling with reparameterization trick\n",
    "def sample_z(args):\n",
    "    mu, sigma = args\n",
    "    batch     = tf.keras.backend.shape(text_mu)[0]\n",
    "    dim       = tf.keras.backend.int_shape(text_mu)[1]\n",
    "    eps       = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return text_mu + tf.keras.backend.exp(text_sigma / 2) * eps\n",
    "\n",
    "z = tf.keras.layers.Lambda(sample_z, output_shape=(len(encoder.get_vocabulary()), ), name='z')([text_mu, text_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = tf.keras.Model(encoder_input, [text_mu, text_sigma, z], name='TextCompressionModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TextCompressionModel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 3500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 3500, 64)     320         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 128), (None, 66048       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            65          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "text_latent_mu (Dense)          (None, 5)            10          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "text_latent_sigma (Dense)       (None, 5)            10          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 5)            0           text_latent_mu[0][0]             \n",
      "                                                                 text_latent_sigma[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 74,709\n",
      "Trainable params: 74,709\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input       = tf.keras.layers.Input(shape=(len(encoder.get_vocabulary()), ), name='decoder_input')\n",
    "dense_layer         = tf.keras.layers.Dense(64, activation='relu')(decoder_input)\n",
    "embedding_layer     = tf.keras.layers.Embedding(input_dim=64, output_dim=MAX_SEQUENCE_LENGHT, mask_zero=True)(dense_layer)\n",
    "LTSM_layer          = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(embedding_layer)\n",
    "final_output_dense  = tf.keras.layers.Dense(MAX_SEQUENCE_LENGHT, activation='relu')(LTSM_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TextDecoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                384       \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 64, 3500)          224000    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 128)               1825280   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3500)              451500    \n",
      "=================================================================\n",
      "Total params: 2,501,164\n",
      "Trainable params: 2,501,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_decoder = tf.keras.Model(decoder_input, final_output_dense, name='TextDecoder')\n",
    "text_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE - Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Text-VAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 3500)]            0         \n",
      "_________________________________________________________________\n",
      "TextCompressionModel (Functi [(None, 5), (None, 5), (N 74709     \n",
      "_________________________________________________________________\n",
      "TextDecoder (Functional)     (None, 3500)              2501164   \n",
      "=================================================================\n",
      "Total params: 2,575,873\n",
      "Trainable params: 2,575,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate VAE\n",
    "tweet_vae_outputs  = text_decoder(text_encoder(encoder_input)[2])\n",
    "tweets_vae         = tf.keras.Model(encoder_input, tweet_vae_outputs, name='Text-VAE')\n",
    "tweets_vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are calcuating the binary crossentropy here.\n",
    "KL Divergence and Reconstruction are the two\n",
    "metrics which we are using to make prediction.\n",
    "\"\"\"\n",
    "def tweets_kl_reconstruction_loss(true, pred):\n",
    "    # Reconstruction loss\n",
    "    reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * input_shape[0]\n",
    "    # KL divergence loss\n",
    "    kl_loss = -0.5 * (1 + sigma - K.square(mu) - K.exp(sigma))\n",
    "    kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "    # Total loss = 50% rec + 50% KL divergence loss\n",
    "    return (reconstruction_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are using the adam optimizer from Keras in combination\n",
    "of our own defined loss function which is the mean of\n",
    "reconstruction loss and the KL divergence.\n",
    "\"\"\"\n",
    "tweets_vae.compile(optimizer='adam', loss=tweets_kl_reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 3500), dtype=int64, numpy=\n",
       "array([[2, 2, 2, ..., 0, 0, 0],\n",
       "       [3, 3, 3, ..., 0, 0, 0],\n",
       "       [2, 2, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [3, 3, 3, ..., 0, 0, 0],\n",
       "       [3, 4, 4, ..., 0, 0, 0],\n",
       "       [2, 3, 3, ..., 0, 0, 0]], dtype=int64)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [10,3500], In[1]: [9,9] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-6a25e5909a65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m vae.fit(x = tweet_data, y = tweet_data, \n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mno_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         validation_split = validation_split)\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    804\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    798\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1211\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m   \u001b[1;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2584\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2585\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2587\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2945\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m       \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m       loss = self.compiled_loss(\n\u001b[0;32m    749\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m--> 385\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m--> 385\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m     return core_ops.dense(\n\u001b[0m\u001b[0;32m   1194\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\ops\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m   \u001b[1;31m# Broadcast kernel to inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5622\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5623\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5624\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5625\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5626\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [10,3500], In[1]: [9,9] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "history = vae.fit(x = tweet_data, y = tweet_data, \n",
    "        epochs = no_epochs, \n",
    "        batch_size = batch_size, \n",
    "        validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tweets = vae.predict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function is being used to print the original tweet\n",
    "and the predicted tweet string side by side for comparison.\n",
    "\"\"\"\n",
    "for n in range(1):\n",
    "    print(\"Original: \", tweets_dna[n])\n",
    "    print(\"Processed: \", \" \".join(vocab[prediction_tweets[n]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
