{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_digital_dna_from_tweets(tweets_df):\n",
    "    '''For each user id in tweets_df return a digital DNA string based on posting behaviour.'''\n",
    "    \n",
    "    # Add columns for counts of tweets, replies and retweets.\n",
    "    tweets_df['num_retweets'] = np.where(tweets_df['retweeted_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_replies'] = np.where(tweets_df['in_reply_to_status_id'] == 0, 0, 1)\n",
    "    tweets_df['num_tweets'] = np.where((tweets_df['num_retweets'] == 0) & (tweets_df['num_replies'] == 0), 1, 0)\n",
    "    \n",
    "    tweets = tweets_df['num_tweets'] == 1\n",
    "    retweets = tweets_df['num_retweets'] == 1\n",
    "    replies = tweets_df['num_replies'] == 1\n",
    "\n",
    "    # DNA alphabet for tweet (A), retweet (C) and reply (T).\n",
    "    tweets_df.loc[:, 'DNA'] = np.where(retweets, ' C', np.where(replies, ' T', ' A'))\n",
    "\n",
    "    # Sort tweets by timestamp.\n",
    "    tweets_df = tweets_df[['user_id', 'timestamp', 'DNA']]\n",
    "    tweets_df = tweets_df.sort_values(by=['timestamp'])\n",
    "\n",
    "    # Create digital DNA string for account.\n",
    "    dna = tweets_df.groupby(by=['user_id'])['DNA'].agg(lambda x: ''.join(x))\n",
    "    \n",
    "    return dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweets = pd.read_csv('dataset/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dna = create_digital_dna_from_tweets(gen_tweets).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part is being used to generate vocabulory which will be used to\n",
    "convert the text into indices. Then this data can be converted to\n",
    "matrices and fed to the learning models.\n",
    "Sequence legth is set by checkcing the maximum lenth of string in the\n",
    "dataset so that we don't have to lose any detail which help in\n",
    "converting the representation back to the original text.\n",
    "\"\"\"\n",
    "VOCAB_SIZE = 5\n",
    "MAX_SEQUENCE_LENGHT = 3500\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE, output_sequence_length=MAX_SEQUENCE_LENGHT)\n",
    "encoder.adapt(tweets_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '[UNK]' 'a' 'c' 't']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking if the generated tokens are right which\n",
    "will be used as terms for strigs.\n",
    "\"\"\"\n",
    "vocab = np.array(encoder.get_vocabulary())\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A T A A A A A A T T A A A T A T A A A T A A A T A A T A T T A T T A A A A A A A A A A A A A A A A A A A A T A A A A A A T A A A A A A A A A A A A A A A A T A A T A T A A A A A A T A A A A A A A A A A A A A A A A A T A A T T A A A A A T T A A T T T A A A T A A A A A T A T A A A A A A A A A A T T A T A T T T A T A A A T A T A A A T A A A A A A A T A A A A A T T A A T A A A A T A A A A T A A A A T T A T T T T A T T T T A A A A T T A A A T A T T A T A A A A A T T A A A T T A A T T A T T T A T T A A T T A A T T T T T A T A A T T T A A T T A T T T T A A T T A A T A A T T T T T T A A A A T A T A T T A T A T T A A A A A A A T T T T A T A T A A T A A A A T T T T T T T T T T T T T T T T T T T A T A T T A T A T T T T T A T T A A A A T A A T T A A T A A T A A T A A A T A A A A A A T T A A A A A T T T A C A T C A A C A A A C T A T A C T C A T C T A T T A A A A A T A C T T C A A A C C A A C C C C A A T A A A T A A A A A A A C C C A A C T T T T A A A A A A A A A A A A T A A A A A T A A A A A A A A A A A A C A A C C A C A A A A A C A C T T A T A A C C A A A C A C A A A A A A A A A A A A A A A A A A A A A A A T A T A A C C C C C C A A C T A C A C A C C A A A A A C A C C C C A A A\n",
      "Processed:  a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a t a a a a a a t t a a a t a t a a a t a a a t a a t a t t a t t a a a a a a a a a a a a a a a a a a a a t a a a a a a t a a a a a a a a a a a a a a a a t a a t a t a a a a a a t a a a a a a a a a a a a a a a a a t a a t t a a a a a t t a a t t t a a a t a a a a a t a t a a a a a a a a a a t t a t a t t t a t a a a t a t a a a t a a a a a a a t a a a a a t t a a t a a a a t a a a a t a a a a t t a t t t t a t t t t a a a a t t a a a t a t t a t a a a a a t t a a a t t a a t t a t t t a t t a a t t a a t t t t t a t a a t t t a a t t a t t t t a a t t a a t a a t t t t t t a a a a t a t a t t a t a t t a a a a a a a t t t t a t a t a a t a a a a t t t t t t t t t t t t t t t t t t t a t a t t a t a t t t t t a t t a a a a t a a t t a a t a a t a a t a a a t a a a a a a t t a a a a a t t t a c a t c a a c a a a c t a t a c t c a t c t a t t a a a a a t a c t t c a a a c c a a c c c c a a t a a a t a a a a a a a c c c a a c t t t t a a a a a a a a a a a a t a a a a a t a a a a a a a a a a a a c a a c c a c a a a a a c a c t t a t a a c c a a a c a c a a a a a a a a a a a a a a a a a a a a a a a t a t a a c c c c c c a a c t a c a c a c c a a a a a c a c c c c a a a                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking if the original and the processed data\n",
    "because presence of unknown chunks would make it\n",
    "impossible to convert data back to text.\n",
    "\"\"\"\n",
    "encoded_example = encoder(tweets_dna)[:3].numpy()\n",
    "\n",
    "for n in range(1):\n",
    "    print(\"Original: \", tweets_dna[n])\n",
    "    print(\"Processed: \", \" \".join(vocab[encoded_example[n]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input       = tf.keras.layers.Input(shape=(encoder(tweets_dna).shape[1], ))\n",
    "embedding_layer     = tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True)(encoder_input)\n",
    "LTSM_layer          = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(embedding_layer)\n",
    "dense_layer         = tf.keras.layers.Dense(64, activation='relu')(LTSM_layer)\n",
    "text_mu             = tf.keras.layers.Dense(len(encoder.get_vocabulary()), name='text_latent_mu')(dense_layer)\n",
    "text_sigma          = tf.keras.layers.Dense(len(encoder.get_vocabulary()), name='text_latent_sigma')(dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling with reparameterization trick\n",
    "def sample_z(args):\n",
    "    mu, sigma = args\n",
    "    batch     = tf.keras.backend.shape(text_mu)[0]\n",
    "    dim       = tf.keras.backend.int_shape(text_mu)[1]\n",
    "    eps       = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return text_mu + tf.keras.backend.exp(text_sigma / 2) * eps\n",
    "\n",
    "z = tf.keras.layers.Lambda(sample_z, output_shape=(len(encoder.get_vocabulary()), ), name='z')([text_mu, text_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(encoder_input, [text_mu, text_sigma, z], name='Text Compression Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Text Compression Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 3500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 3500, 64)     320         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 128)          66048       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "text_latent_mu (Dense)          (None, 5)            325         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "text_latent_sigma (Dense)       (None, 5)            325         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 5)            0           text_latent_mu[0][0]             \n",
      "                                                                 text_latent_sigma[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 75,274\n",
      "Trainable params: 75,274\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([encoder, tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([layer.supports_masking for layer in model_2.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_tweet = tweets_dna[:1]\n",
    "\n",
    "predictions = model_2.predict(sample_tweet)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a sample text with padding\n",
    "\n",
    "padding = \"a \" * 2000\n",
    "predictions = model.predict(np.array([sample_tweet[0], padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 11)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.values.reshape(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(b.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#TODO\n",
    "Get a word_dict to convert all of the sequences to using the same pattern.\n",
    "So that the conversion back to data gets easier if necessary.\n",
    "This cell is the starter code to convert 'url', 'description' and 'tweets_dna'\n",
    "to a consistent sequence of numbers.\n",
    "\"\"\"\n",
    "\n",
    "t  = Tokenizer()\n",
    "fit_text = 'CTCCCAACACTCCACCCACCAAAAATCATACAATATTATAAACCAT'\n",
    "t.fit_on_texts(fit_text)\n",
    "test_text = 'CTCCCAACACTCCACCCACCAAAAATCATACAATATTATAAACCAT'\n",
    "sequences = t.texts_to_sequences(test_text)\n",
    "\n",
    "print(\"word_index : \",t.word_index)\n",
    "print(\"sequences : \",sequences,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
